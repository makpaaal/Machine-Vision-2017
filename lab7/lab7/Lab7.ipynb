{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern recognition: Lab 7\n",
    "### Tasks:\n",
    "* Plot the error\n",
    "* Model XOR with the help of sigmoid\n",
    "* Add moments rule to learning equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 1\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-k*x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return x*(1.0-x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n",
      "[0 0] [  5.09816784e-06]\n",
      "[0 1] [ 0.99594055]\n",
      "[1 0] [ 0.99748766]\n",
      "[1 1] [  5.33629818e-05]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = tanh\n",
    "        self.activation_prime = tanh_prime\n",
    "\n",
    "        # Set weights\n",
    "        self.weights = []\n",
    "        # layers = [2,2,1]\n",
    "        # range of weight values (-1,1)\n",
    "        # input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "        \n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "        # output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "        # Add column of ones to X\n",
    "        # This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "         \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "\n",
    "            for l in range(len(self.weights)):\n",
    "                    dot_value = np.dot(a[l], self.weights[l])\n",
    "                    activation = self.activation(dot_value)\n",
    "                    a.append(activation)\n",
    "            # output layer\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "            # we need to begin at the second to last layer \n",
    "            # (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "            # reverse\n",
    "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "            # backpropagation\n",
    "            # 1. Multiply its output delta and input activation \n",
    "            #    to get the gradient of the weight.\n",
    "            # 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "\n",
    "            if k % 10000 == 0: \n",
    "                print('epochs:', k)\n",
    "\n",
    "    def predict(self, x): \n",
    "    \n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))      \n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "#     X = np.array([[-1, -1],\n",
    "#                   [-1, 1],\n",
    "#                   [1, -1],\n",
    "#                   [1, 1]])\n",
    "#     y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "epochs: 10000\n",
      "epochs: 20000\n",
      "epochs: 30000\n",
      "epochs: 40000\n",
      "epochs: 50000\n",
      "epochs: 60000\n",
      "epochs: 70000\n",
      "epochs: 80000\n",
      "epochs: 90000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEKCAYAAAAW8vJGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14436df470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] [ 0.00874247  0.01192543  0.00712614]\n",
      "[0 1] [ 0.99002883  0.98216287  0.99366965]\n",
      "[1 0] [ 0.9847946   0.98548116  0.98744828]\n",
      "[1 1] [ 0.01583124  0.01950763  0.01392153]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.activation = sigmoid\n",
    "        self.activation_prime = sigmoid_prime\n",
    "\n",
    "# Set weights\n",
    "        self.weights = []\n",
    "# layers = [2,2,1]\n",
    "# range of weight values (-1,1)\n",
    "# input and hidden layers - random((2+1, 2+1)) : 3 x 3\n",
    "\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
    "            self.weights.append(r)\n",
    "# output layer - random((2+1, 1)) : 3 x 1\n",
    "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=100000):\n",
    "# Add column of ones to X\n",
    "# This is to add the bias unit to the input layer\n",
    "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
    "        X = np.concatenate((ones.T, X), axis=1)\n",
    "        myList=[]\n",
    "        avList=[]\n",
    "\n",
    "\n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    "    \n",
    "            for l in range(len(self.weights)):\n",
    "                dot_value = np.dot(a[l], self.weights[l])\n",
    "                activation = self.activation(dot_value)\n",
    "                a.append(activation)\n",
    "# output layer\n",
    "\n",
    "\n",
    "            error = y[i] - a[-1]\n",
    "            myList.append(np.sum(error**2))# mean squard error MSE\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# we need to begin at the second to last layer\n",
    "# (a layer before the output layer)\n",
    "            for l in range(len(a) - 2, 0, -1):\n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "\n",
    "# reverse\n",
    "# [level3(output)->level2(hidden)] => [level2(hidden)->level3(output)]\n",
    "            deltas.reverse()\n",
    "\n",
    "# backpropagation\n",
    "# 1. Multiply its output delta and input activation\n",
    "# to get the gradient of the weight.\n",
    "# 2. Subtract a ratio (percentage) of the gradient from the weight.\n",
    "\n",
    "            cnt = 0\n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                cnt =cnt + layer.T.dot(delta)\n",
    "                self.weights[i] =self.weights[i]+ learning_rate * cnt#  momentum\n",
    "            t = np.average(myList)\n",
    "            avList.append(t)\n",
    "            if k % 10000 == 0:\n",
    "                print('epochs:', k)\n",
    "                t = np.average(myList)\n",
    "                avList.append(t)\n",
    "\n",
    "# plt.show()\n",
    "#print(myList)\n",
    "\n",
    "#plt.plot(myList[1])\n",
    "        plt.plot(avList)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('error')\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        a = np.concatenate((np.ones(1).T, np.array(x)))\n",
    "\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    nn = NeuralNetwork([2,2,1])\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "    y = np.array([0, 1, 1,0])\n",
    "# X = np.array([[-1, -1],\n",
    "# [-1, 1],\n",
    "# [1, -1],\n",
    "# [1, 1]])\n",
    "# y = np.array([0, 1, 1, 0])\n",
    "\n",
    "    nn.fit(X, y)\n",
    "    for e in X:\n",
    "        print(e,nn.predict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
